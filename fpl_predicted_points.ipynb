{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 39.13325\n",
      "Predictions: [9.32 5.71]\n",
      "Actual Points: [18  4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example DataFrame with expected data\n",
    "data = {\n",
    "    'minutes': [90, 90, 90, 90, 90, 90, 90, 90, 90, 90],\n",
    "    'xG': [0.6, 0.1, 0.0, 1.1, 0.1, 0.5, 0.2, 1.0, 0.9, 0.1],\n",
    "    'xA': [0.6, 0.1, 0.0, 0.3, 0.1, 0.5, 0.2, 0.2, 0.1, 0.1],\n",
    "    'clean_sheets': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'opponent_strength': [1, 3, 5, 2, 2, 4, 5, 3, 1, 1],\n",
    "    'home_away': [0, 1, 0, 1, 0, 0, 1, 0, 1, 1],\n",
    "    'fpl_points': [2, 4, 5, 11, 2, 8, 9, 15, 18, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define features and target\n",
    "X = df[['minutes', 'xG', 'xA', 'clean_sheets', 'opponent_strength', 'home_away']]\n",
    "y = df['fpl_points']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Predictions: {predictions}')\n",
    "print(f'Actual Points: {y_test.values}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mean Squared Error: 9.940159999999999\n",
      "   Predicted Points  Actual Points\n",
      "0              4.34              2\n",
      "1              5.71              4\n",
      "2              5.65              5\n",
      "3             10.64             11\n",
      "4              3.56              2\n",
      "5              7.69              8\n",
      "6              8.04              9\n",
      "7             11.60             15\n",
      "8              9.32             18\n",
      "9              4.31              4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example DataFrame with expected data\n",
    "data = {\n",
    "    'minutes': [90, 90, 90, 90, 90, 90, 90, 90, 90, 90],\n",
    "    'xG': [0.6, 0.1, 0.0, 1.1, 0.1, 0.5, 0.2, 1.0, 0.9, 0.1],\n",
    "    'xA': [0.6, 0.1, 0.0, 0.3, 0.1, 0.5, 0.2, 0.2, 0.1, 0.1],\n",
    "    'clean_sheets': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'opponent_strength': [1, 3, 5, 2, 2, 4, 5, 3, 1, 1],\n",
    "    'home_away': [0, 1, 0, 1, 0, 0, 1, 0, 1, 1],\n",
    "    'fpl_points': [2, 4, 5, 11, 2, 8, 9, 15, 18, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define features and target\n",
    "X = df[['minutes', 'xG', 'xA', 'clean_sheets', 'opponent_strength', 'home_away']]\n",
    "y = df['fpl_points']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the entire scaled dataset\n",
    "all_predictions = model.predict(X_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y, all_predictions)\n",
    "print(f'Total Mean Squared Error: {mse}')\n",
    "\n",
    "# Display predictions and actual points for all data\n",
    "results_df = pd.DataFrame({'Predicted Points': all_predictions, 'Actual Points': y})\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "Optimized MSE: 89.22657702452216\n",
      "Predictions: [4.6575575 4.6575575]\n",
      "Actual Points: [18  4]\n",
      "CV Average MSE: 27.071315726859986\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Example DataFrame with expected data\n",
    "data = {\n",
    "    'minutes': [90, 90, 90, 90, 90, 90, 90, 90, 90, 90],\n",
    "    'xG': [0.6, 0.1, 0.0, 1.1, 0.1, 0.5, 0.2, 1.0, 0.9, 0.1],\n",
    "    'xA': [0.6, 0.1, 0.0, 0.3, 0.1, 0.5, 0.2, 0.2, 0.1, 0.1],\n",
    "    'clean_sheets': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'opponent_strength': [1, 3, 5, 2, 2, 4, 5, 3, 1, 1],\n",
    "    'home_away': [0, 1, 0, 1, 0, 0, 1, 0, 1, 1],\n",
    "    'fpl_points': [2, 4, 5, 11, 2, 8, 9, 15, 18, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Feature engineering\n",
    "df['xG_per_minute'] = df['xG'] * df['minutes'] / 90  # Normalized by minutes in a full match\n",
    "df['interaction'] = df['xG'] * df['opponent_strength']\n",
    "\n",
    "# Define features and target\n",
    "X = df[['minutes', 'xG', 'xA', 'clean_sheets', 'opponent_strength', 'home_away', 'xG_per_minute', 'interaction']]\n",
    "y = df['fpl_points']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model setup with XGBoost\n",
    "model = XGBRegressor(objective ='reg:squarederror', n_estimators=100, learning_rate=0.05, max_depth=5)\n",
    "\n",
    "# Grid Search for Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predictions and Evaluation\n",
    "predictions = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Optimized MSE: {mse}')\n",
    "print(f'Predictions: {predictions}')\n",
    "print(f'Actual Points: {y_test.values}')\n",
    "\n",
    "# Cross-Validation\n",
    "cv_scores = cross_val_score(best_model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'CV Average MSE: {-np.mean(cv_scores)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Mean Squared Error: 2.5949899999999997\n",
      "   Predicted Points  Actual Points\n",
      "0              5.79              2\n",
      "1              3.44              4\n",
      "2              4.78              5\n",
      "3             12.47             11\n",
      "4              2.69              2\n",
      "5              8.79              8\n",
      "6              7.79              9\n",
      "7             14.33             15\n",
      "8             15.56             18\n",
      "9              3.69              4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example DataFrame with expected data\n",
    "data = {\n",
    "    'minutes': [90, 90, 90, 90, 90, 90, 90, 90, 90, 90],\n",
    "    'xG': [0.6, 0.1, 0.0, 1.1, 0.1, 0.5, 0.2, 1.0, 0.9, 0.1],\n",
    "    'xA': [0.6, 0.1, 0.0, 0.3, 0.1, 0.5, 0.2, 0.2, 0.1, 0.1],\n",
    "    'clean_sheets': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'opponent_strength': [1, 3, 5, 2, 2, 4, 5, 3, 1, 1],\n",
    "    'home_away': [0, 1, 0, 1, 0, 0, 1, 0, 1, 1],\n",
    "    'fpl_points': [2, 4, 5, 11, 2, 8, 9, 15, 18, 4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Feature engineering\n",
    "df['xG_per_minute'] = df['xG'] * df['minutes'] / 90  # Normalized by minutes in a full match\n",
    "df['interaction'] = df['xG'] * df['opponent_strength']\n",
    "\n",
    "# Define features and target\n",
    "X = df[['minutes', 'xG', 'xA', 'clean_sheets', 'opponent_strength', 'home_away', 'xG_per_minute', 'interaction']]\n",
    "y = df['fpl_points']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the entire dataset\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Predict using the entire scaled dataset\n",
    "all_predictions = model.predict(X_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y, all_predictions)\n",
    "print(f'Total Mean Squared Error: {mse}')\n",
    "\n",
    "# Display predictions and actual points for all data\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted Points': all_predictions,\n",
    "    'Actual Points': y\n",
    "})\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted FPL Points for Bruno Fernandes in the Next Game: 7.468000000000001\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Historical data example (simplified for Bruno Fernandes)\n",
    "data = {\n",
    "    'minutes': [90] * 10,\n",
    "    'xG': [0.2, 0.1, 0.4, 0.3, 0.2, 0.15, 0.25, 0.05, 0.3, 0.2],\n",
    "    'xA': [0.1, 0.2, 0.05, 0.15, 0.1, 0.2, 0.1, 0.05, 0.15, 0.1],\n",
    "    'clean_sheets': [1, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
    "    'opponent_strength': [1, 3, 2, 4, 2, 3, 2, 3, 4, 3],  # 1 is strongest, 4 is weakest\n",
    "    'home_away': [1, 0, 1, 0, 1, 1, 0, 1, 0, 1],\n",
    "    'fpl_points': [6, 7, 11, 10, 7, 8, 5, 12, 9, 6]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define features and target\n",
    "X = df[['minutes', 'xG', 'xA', 'clean_sheets', 'opponent_strength', 'home_away']]\n",
    "y = df['fpl_points']\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize and train the RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Upcoming game data including contextual predictions\n",
    "upcoming_game_data = {\n",
    "    'minutes': [90],  # Expected to play full time\n",
    "    'xG': [2.2 * (0.3 / 3)],  # Bruno's average xG contribution considering team's predicted goals\n",
    "    'xA': [2.2 * (0.2 / 3)],  # Bruno's average xA contribution\n",
    "    'clean_sheets': [0.4],  # Team's predicted clean sheet probability\n",
    "    'opponent_strength': [19],  # 2nd worst in the league, scaled similarly\n",
    "    'home_away': [0]  # Away game\n",
    "}\n",
    "\n",
    "upcoming_game_df = pd.DataFrame(upcoming_game_data)\n",
    "upcoming_game_scaled = scaler.transform(upcoming_game_df)\n",
    "\n",
    "# Predict using the model\n",
    "predicted_points = model.predict(upcoming_game_scaled)\n",
    "print(f'Predicted FPL Points for Bruno Fernandes in the Next Game: {predicted_points[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted FPL Points for Bruno Fernandes in the Next Game: 3.914000000000003\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Example DataFrame with simplified historical data\n",
    "data = {\n",
    "    'xG': [0.2, 0.1, 0.4, 0.3, 0.2, 0.15, 0.25, 0.05, 0.3, 0.2],\n",
    "    'xA': [0.1, 0.2, 0.05, 0.15, 0.1, 0.2, 0.1, 0.05, 0.15, 0.1],\n",
    "    'clean_sheets': [1, 0, 0, 1, 1, 0, 0, 1, 1, 0],  # Assume this is for the whole team, applicable if midfielder\n",
    "    'fpl_points': [6, 7, 11, 10, 7, 8, 5, 12, 9, 6]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define features and target\n",
    "X = df[['xG', 'xA', 'clean_sheets']]\n",
    "\n",
    "# Custom scoring function based on FPL rules\n",
    "def calculate_fpl_points(row):\n",
    "    points = 0\n",
    "    points += row['xG'] * 5  # 5 points per goal for midfielders\n",
    "    points += row['xA'] * 3  # 3 points per assist\n",
    "    points += row['clean_sheets'] * 1  # 1 point for a clean sheet for midfielders\n",
    "    points += 2  # Assuming Bruno plays more than 60 minutes\n",
    "    return points\n",
    "\n",
    "# Apply scoring function to generate expected points from historical data\n",
    "df['calculated_points'] = df.apply(calculate_fpl_points, axis=1)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train the RandomForestRegressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_scaled, df['calculated_points'])\n",
    "\n",
    "# Hypothetical upcoming game data with predicted stats\n",
    "upcoming_game_data = {\n",
    "    'xG': [0.25],  # Predicted xG for the game\n",
    "    'xA': [0.15],  # Predicted xA for the game\n",
    "    'clean_sheets': [0.4]  # Clean sheet probability converted to expected value (assuming binary input needed)\n",
    "}\n",
    "\n",
    "# Prepare data frame for prediction\n",
    "upcoming_game_df = pd.DataFrame(upcoming_game_data)\n",
    "upcoming_game_scaled = scaler.transform(upcoming_game_df)\n",
    "\n",
    "# Predict using the trained model\n",
    "predicted_points = model.predict(upcoming_game_scaled)\n",
    "print(f'Predicted FPL Points for Bruno Fernandes in the Next Game: {predicted_points[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted FPL Points for Bruno Fernandes in the Next Game: 7.625\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Historical data example\n",
    "data = {\n",
    "    'xG': [0.2, 0.1, 0.4, 0.3, 0.2, 0.15, 0.25, 0.05, 0.3, 0.2],\n",
    "    'xA': [0.1, 0.2, 0.05, 0.15, 0.1, 0.2, 0.1, 0.05, 0.15, 0.1],\n",
    "    'clean_sheets': [1, 0, 0, 1, 1, 0, 0, 1, 1, 0],\n",
    "    'bonus': [3, 1, 2, 3, 1, 0, 2, 1, 3, 2],  # Simulated bonus points\n",
    "    'fpl_points': [6, 7, 11, 10, 7, 8, 5, 12, 9, 6]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Features and target for prediction\n",
    "X = df[['xG', 'xA', 'clean_sheets']]\n",
    "y = df['fpl_points'] + df['bonus']  # Including bonus points in the target\n",
    "\n",
    "# Scaler and RandomForestRegressor setup\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Upcoming game prediction setup\n",
    "upcoming_game_data = {\n",
    "    'xG': [0.25],  # Predicted xG for the game\n",
    "    'xA': [0.15],  # Predicted xA for the game\n",
    "    'clean_sheets': [0.4]  # Converted probability\n",
    "}\n",
    "\n",
    "upcoming_game_df = pd.DataFrame(upcoming_game_data)\n",
    "upcoming_game_scaled = scaler.transform(upcoming_game_df)\n",
    "\n",
    "# Prediction\n",
    "predicted_points = model.predict(upcoming_game_scaled)\n",
    "print(f'Predicted FPL Points for Bruno Fernandes in the Next Game: {predicted_points[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted FPL Points with Bonus for Bruno Fernandes in the Next Game: 6.390500000000005\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Example DataFrame with simplified historical data\n",
    "data = {\n",
    "    # 'xG': [0.2, 0.1, 0.4, 0.3, 0.2, 0.15, 0.25, 0.05, 0.3, 0.2],\n",
    "    # 'xA': [0.1, 0.2, 0.05, 0.15, 0.1, 0.2, 0.1, 0.05, 0.15, 0.1],\n",
    "    # 'clean_sheets': [1, 0, 0, 1, 1, 0, 0, 1, 1, 0],  # Assume Bruno is a midfielder\n",
    "    'xG': [0.6, 0.1, 0.0, 1.1, 0.1, 0.5, 0.2, 1.0, 0.9, 0.1],\n",
    "    'xA': [0.6, 0.1, 0.0, 0.3, 0.1, 0.5, 0.2, 0.2, 0.1, 0.1],\n",
    "    'clean_sheets': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'bonus': [0, 0, 0, 3, 0, 1, 2, 3, 3, 2]  # Simulated bonus points\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Modify scoring function to reflect FPL rules more realistically\n",
    "def calculate_fpl_points(row):\n",
    "    points = 2  # Assume at least 60 minutes of playtime\n",
    "    points += row['xG'] * 5  # Goals by midfielders score 5 points\n",
    "    points += row['xA'] * 3  # Each assist scores 3 points\n",
    "    points += row['clean_sheets'] * 1  # 1 point for a clean sheet for midfielders\n",
    "    return points\n",
    "\n",
    "# Applying scoring function to generate expected points from historical data\n",
    "df['calculated_points'] = df.apply(calculate_fpl_points, axis=1)\n",
    "\n",
    "# Features and target\n",
    "X = df[['xG', 'xA', 'clean_sheets']]\n",
    "y = df['calculated_points']  # Target now includes calculated points instead of raw fpl_points\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train the RandomForestRegressor model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Upcoming game prediction\n",
    "upcoming_game_data = {\n",
    "    'xG': [0.95],  # Reduced expected xG\n",
    "    'xA': [0.10],  # Reduced expected xA\n",
    "    'clean_sheets': [0.4]  # Reduced probability of clean sheets\n",
    "}\n",
    "\n",
    "def estimate_bps(row):\n",
    "    bps_score = 0\n",
    "    bps_score += row['xG'] * 25  # Assuming higher weight for goals\n",
    "    bps_score += row['xA'] * 15  # Assuming assists also carry significant weight\n",
    "    bps_score += row['clean_sheets'] * 5  # Add for clean sheets if applicable\n",
    "    return bps_score\n",
    "\n",
    "def assign_bonus_points(bps_scores, n_players=11):\n",
    "    sorted_scores = sorted(bps_scores, reverse=True)\n",
    "    bonus_points = [0] * len(bps_scores)\n",
    "    if len(sorted_scores) > 0:\n",
    "        max_score = sorted_scores[0]\n",
    "        bonus_points[bps_scores.index(max_score)] = 3  # 3 points to highest BPS\n",
    "    if len(sorted_scores) > 1:\n",
    "        second_score = sorted_scores[1]\n",
    "        bonus_points[bps_scores.index(second_score)] = 2  # 2 points to second highest BPS\n",
    "    if len(sorted_scores) > 2:\n",
    "        third_score = sorted_scores[2]\n",
    "        bonus_points[bps_scores.index(third_score)] = 1  # 1 point to third highest BPS\n",
    "    return bonus_points\n",
    "\n",
    "# Simulating within team or match context - simplification\n",
    "upcoming_game_df['bps_score'] = upcoming_game_df.apply(estimate_bps, axis=1)\n",
    "bps_scores = list(upcoming_game_df['bps_score'])  # Assuming this is just for one team or key players\n",
    "bonus_points = assign_bonus_points(bps_scores)\n",
    "\n",
    "# Add bonus points to the predicted points\n",
    "predicted_points_with_bonus = predicted_points[0] + bonus_points[0]\n",
    "print(f'Predicted FPL Points with Bonus for Bruno Fernandes in the Next Game: {predicted_points_with_bonus}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted FPL Points for Bruno Fernandes in the Next Game: 3.064000000000003\n",
      "Predicted FPL Points with Bonus for Bruno Fernandes in the Next Game: 6.064000000000004\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Data setup\n",
    "data = {\n",
    "    'xG': [0.6, 0.1, 0.0, 1.1, 0.1, 0.5, 0.2, 1.0, 0.9, 0.1],\n",
    "    'xA': [0.6, 0.1, 0.0, 0.3, 0.1, 0.5, 0.2, 0.2, 0.1, 0.1],\n",
    "    'clean_sheets': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'bonus': [0, 0, 0, 3, 0, 1, 2, 3, 3, 2]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Scoring function\n",
    "def calculate_fpl_points(row):\n",
    "    points = 2  # Base points for playing over 60 minutes\n",
    "    points += row['xG'] * 5  # Goals by midfielders\n",
    "    points += row['xA'] * 3  # Assists\n",
    "    points += row['clean_sheets']  # Clean sheets for midfielders\n",
    "    return points\n",
    "\n",
    "df['calculated_points'] = df.apply(calculate_fpl_points, axis=1)\n",
    "\n",
    "# Features and target\n",
    "X = df[['xG', 'xA', 'clean_sheets']]\n",
    "y = df['calculated_points']\n",
    "\n",
    "# Scaling and model training\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_scaled, y)\n",
    "\n",
    "# Upcoming game prediction setup\n",
    "upcoming_game_data = {\n",
    "    'xG': [0.25],  # Adjusted expected xG\n",
    "    'xA': [0.07],  # Adjusted expected xA\n",
    "    'clean_sheets': [0.4]  # Adjusted probability of clean sheets\n",
    "}\n",
    "upcoming_game_df = pd.DataFrame(upcoming_game_data)\n",
    "upcoming_game_scaled = scaler.transform(upcoming_game_df)\n",
    "\n",
    "# Predict using the trained model\n",
    "predicted_points = model.predict(upcoming_game_scaled)\n",
    "print(f'Predicted FPL Points for Bruno Fernandes in the Next Game: {predicted_points[0]}')\n",
    "\n",
    "# Bonus point adjustment\n",
    "upcoming_game_df['bps_score'] = upcoming_game_df.apply(estimate_bps, axis=1)\n",
    "bps_scores = list(upcoming_game_df['bps_score'])  # Assuming this is just for one team or key players\n",
    "bonus_points = assign_bonus_points(bps_scores)\n",
    "\n",
    "# Combine predicted points with bonus\n",
    "predicted_points_with_bonus = predicted_points[0] + bonus_points[0]\n",
    "print(f'Predicted FPL Points with Bonus for Bruno Fernandes in the Next Game: {predicted_points_with_bonus}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mimport\u001b[39;00m LGBMRegressor\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m \u001b[39m# Sample DataFrame for Bruno Fernandes\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m data \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=8'>9</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mxG\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.6\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m1.1\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m1.0\u001b[39m, \u001b[39m0.9\u001b[39m, \u001b[39m0.1\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mxA\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.6\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.0\u001b[39m, \u001b[39m0.3\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.5\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.2\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m0.1\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfpl_points\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m11\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m12\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m6\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#X12sdW50aXRsZWQ%3D?line=14'>15</a>\u001b[0m }\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Sample DataFrame for Bruno Fernandes\n",
    "data = {\n",
    "    'xG': [0.6, 0.1, 0.0, 1.1, 0.1, 0.5, 0.2, 1.0, 0.9, 0.1],\n",
    "    'xA': [0.6, 0.1, 0.0, 0.3, 0.1, 0.5, 0.2, 0.2, 0.1, 0.1],\n",
    "    'clean_sheets': [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "    'opponent_strength': [2, 8, 6, 4, 5, 3, 7, 1, 9, 10],  # 10 being the strongest\n",
    "    'bonus': [0, 0, 0, 3, 0, 1, 2, 3, 3, 2],  # Actual bonus points collected\n",
    "    'fpl_points': [6, 7, 11, 10, 7, 8, 5, 12, 9, 6]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Prepare features and target\n",
    "X = df[['xG', 'xA', 'clean_sheets', 'opponent_strength']]\n",
    "y = df['fpl_points'] + df['bonus']  # Combine points and bonus\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the LGBMRegressor\n",
    "model = LGBMRegressor(n_estimators=100, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Predictions: {predictions}')\n",
    "\n",
    "# Bonus point prediction setup could be refined similarly with a custom approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample data including expected metrics\n",
    "data = {\n",
    "    'xG': [0.6, 0.1, 0.0, 1.1, 0.1, 0.5, 0.2, 1.0, 0.9, 0.1],\n",
    "    'xA': [0.6, 0.1, 0.0, 0.3, 0.1, 0.5, 0.2, 0.2, 0.1, 0.1],\n",
    "    'xCS': [0.2, 0.1, 0.0, 0.4, 0.1, 0.3, 0.2, 0.0, 0.3, 0.2],\n",
    "    'fpl_points': [6, 7, 11, 10, 7, 8, 5, 12, 9, 6]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Expected Points Calculation\n",
    "def calculate_expected_points(xG, xA, xCS):\n",
    "    # Points from goals, assists and clean sheets\n",
    "    points_from_goals = xG * 5  # 5 points per goal for midfielders\n",
    "    points_from_assists = xA * 3  # 3 points per assist\n",
    "    points_from_cleansheets = xCS * 1  # 1 point for a clean sheet (if applicable)\n",
    "    return points_from_goals + points_from_assists + points_from_cleansheets\n",
    "\n",
    "# Add expected points to DataFrame\n",
    "df['expected_points'] = df.apply(lambda row: calculate_expected_points(row['xG'], row['xA'], row['xCS']), axis=1)\n",
    "\n",
    "# Features and target\n",
    "X = df[['xG', 'xA', 'xCS']]\n",
    "y = df['expected_points']\n",
    "\n",
    "# Model Training\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicting and Evaluating the model\n",
    "predicted_points = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted FPL Points for Bruno Fernandes against Burnley: 5.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richard/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the expected performance metrics against Burnley\n",
    "bruno_vs_burnley = np.array([[0.9, 0.9, 0.4]])  # [xG, xA, xCS]\n",
    "\n",
    "# Scale the features using the same scaler used during training\n",
    "bruno_vs_burnley_scaled = scaler.transform(bruno_vs_burnley)\n",
    "\n",
    "# Predict FPL points using the RandomForest model\n",
    "predicted_points_burnley = model.predict(bruno_vs_burnley_scaled)\n",
    "\n",
    "print(f\"Predicted FPL Points for Bruno Fernandes against Burnley: {predicted_points_burnley[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "# base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(current_dir))))\n",
    "new_directory = os.path.join(current_dir, \"data\", \"databases\")\n",
    "\n",
    "# Create a new SQLite database (or connect to an existing one)\n",
    "db_name = os.path.join(new_directory, 'fbref_data_players_latest.db')\n",
    "conn = sqlite3.connect(db_name)\n",
    "test_df_new = pd.read_sql_query('SELECT * FROM general', conn)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0496842fed3252e429d236fd9df9f28ef62eb2f8e7d98cd38ba8d6755488d983"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
